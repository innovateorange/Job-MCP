{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentence-transformers accelerate scikit-learn\n"
      ],
      "metadata": {
        "id": "7GWOchU9ECiZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "t5_model_name = \"google/flan-t5-small\"\n",
        "\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_model_name)\n",
        "\n",
        "def job_fitting_prompt_t5(job_description, resume_text):\n",
        "    prompt = f\"\"\"\n",
        "You are a recruiter. In 2–4 full sentences, explain why this candidate is or is not a good fit for the job.\n",
        "Mention specific skills, experience, and technologies when possible.\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Candidate Resume:\n",
        "{resume_text}\n",
        "\n",
        "Answer (2–4 sentences):\n",
        "\"\"\".strip()\n",
        "\n",
        "    inputs = t5_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    outputs = t5_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=120,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print(\"T5 model ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXlsGi8EEGRa",
        "outputId": "c07d3ae5-8df8-4169-f844-5cd7d71cc4ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5 model ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def job_fitting_prompt_bert(job_description, resume_text):\n",
        "    job_emb = bert_model.encode([job_description])\n",
        "    res_emb = bert_model.encode([resume_text])\n",
        "    sim = cosine_similarity(job_emb, res_emb)[0][0]\n",
        "    return float(sim)\n",
        "\n",
        "print(\"BERT model ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wobyMFU8ER2O",
        "outputId": "32b79874-4d72-4ecb-b23b-115187f0f03e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_desc = \"\"\"\n",
        "We are looking for a backend software engineer with strong experience in Python,\n",
        "REST APIs, SQL databases, and cloud platforms such as AWS or GCP.\n",
        "\"\"\"\n",
        "\n",
        "resume_text = \"\"\"\n",
        "Computer Engineering student with experience building backend services in Python and Flask,\n",
        "working with PostgreSQL databases, and deploying small projects to AWS.\n",
        "Strong problem-solving skills and experience with Git and Linux.\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== T5 job-fit justification ===\")\n",
        "print(job_fitting_prompt_t5(job_desc, resume_text))\n",
        "\n",
        "print(\"\\n=== BERT similarity score ===\")\n",
        "print(job_fitting_prompt_bert(job_desc, resume_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q0vwFSSEVFo",
        "outputId": "187ee5a0-0a6f-4c33-b6c4-e96ddd4d9a65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== T5 job-fit justification ===\n",
            "a computer engineer with strong experience in Python, REST APIs, SQL databases, and cloud platforms\n",
            "\n",
            "=== BERT similarity score ===\n",
            "0.766248881816864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "# ===============================\n",
        "# CONFIG: put your Jooble API key\n",
        "# ===============================\n",
        "JOOBLE_API_KEY = \"0a37febe-753a-4e3c-91ba-f2722abbb82a\"\n",
        "\n",
        "KEYWORDS = \"software engineer OR developer OR backend\"\n",
        "LOCATION = \"United States\"\n",
        "\n",
        "RESULTS_PER_PAGE = 50   # Jooble default page size\n",
        "MAX_PAGES = 10          # safety limit, adjust if needed\n",
        "\n",
        "OUTPUT_CSV = \"job_listings_last_week_jooble.csv\"\n",
        "\n",
        "# Simple tech keyword list for tagging\n",
        "TECH_KEYWORDS = [\n",
        "    \"python\", \"java\", \"javascript\", \"typescript\", \"c++\", \"c#\", \"go\", \"golang\",\n",
        "    \"rust\", \"sql\", \"nosql\", \"aws\", \"azure\", \"gcp\", \"docker\", \"kubernetes\",\n",
        "    \"react\", \"angular\", \"vue\", \"node\", \"linux\", \"bash\", \"shell\", \"git\",\n",
        "    \"ci/cd\", \"tensorflow\", \"pytorch\", \"spark\", \"hadoop\"\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# Helper functions\n",
        "# ===============================\n",
        "\n",
        "def parse_updated_date(updated_str):\n",
        "    \"\"\"\n",
        "    Jooble 'updated' looks like:\n",
        "    '2023-09-15T12:55:35.3870000'\n",
        "    We try to parse it into a datetime.\n",
        "    \"\"\"\n",
        "    if not updated_str:\n",
        "        return None\n",
        "    try:\n",
        "        # trim to 26 chars to handle microseconds safely\n",
        "        trimmed = updated_str[:26]\n",
        "        return datetime.fromisoformat(trimmed)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return datetime.fromisoformat(updated_str.split(\"T\")[0])\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def is_within_last_week(dt):\n",
        "    if dt is None:\n",
        "        return False\n",
        "    now = datetime.now(timezone.utc)\n",
        "    one_week_ago = now - timedelta(days=7)\n",
        "    if dt.tzinfo is None:\n",
        "        dt = dt.replace(tzinfo=timezone.utc)\n",
        "    return dt >= one_week_ago\n",
        "\n",
        "def detect_is_remote(title, location, description):\n",
        "    text = \" \".join([title or \"\", location or \"\", description or \"\"]).lower()\n",
        "    return (\"remote\" in text) or (\"work from home\" in text) or (\"wfh\" in text)\n",
        "\n",
        "def extract_tech_keywords(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    lower = text.lower()\n",
        "    found = sorted({kw for kw in TECH_KEYWORDS if kw in lower})\n",
        "    return \";\".join(found)\n",
        "\n",
        "def fetch_jobs_page(page):\n",
        "    url = f\"https://jooble.org/api/{JOOBLE_API_KEY}\"\n",
        "    payload = {\n",
        "        \"keywords\": KEYWORDS,\n",
        "        \"location\": LOCATION,\n",
        "        \"page\": page,\n",
        "        \"result_on_page\": RESULTS_PER_PAGE\n",
        "    }\n",
        "    resp = requests.post(url, json=payload)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "# ===============================\n",
        "# Main fetching logic\n",
        "# ===============================\n",
        "\n",
        "if not JOOBLE_API_KEY or JOOBLE_API_KEY == \"YOUR_JOOBLE_API_KEY_HERE\":\n",
        "    raise ValueError(\"Please set JOOBLE_API_KEY to your actual key before running this cell.\")\n",
        "\n",
        "all_rows = []\n",
        "\n",
        "for page in range(1, MAX_PAGES + 1):\n",
        "    data = fetch_jobs_page(page)\n",
        "    jobs = data.get(\"jobs\", [])\n",
        "\n",
        "    if not jobs:\n",
        "        break\n",
        "\n",
        "    stop_due_to_date = False\n",
        "\n",
        "    for job in jobs:\n",
        "        updated_str = job.get(\"updated\")\n",
        "        updated_dt = parse_updated_date(updated_str)\n",
        "\n",
        "        # Only keep jobs from the last 7 days\n",
        "        if not is_within_last_week(updated_dt):\n",
        "            stop_due_to_date = True\n",
        "            continue\n",
        "\n",
        "        title = job.get(\"title\", \"\")\n",
        "        company = job.get(\"company\", \"\")\n",
        "        location = job.get(\"location\", \"\")\n",
        "        description = job.get(\"snippet\", \"\") or job.get(\"description\", \"\")\n",
        "        url = job.get(\"link\", \"\")\n",
        "\n",
        "        is_remote = detect_is_remote(title, location, description)\n",
        "        tech_kw = extract_tech_keywords(description)\n",
        "\n",
        "        date_posted = updated_dt.date().isoformat() if updated_dt else \"\"\n",
        "\n",
        "        all_rows.append({\n",
        "            \"job_title\": title,\n",
        "            \"company\": company,\n",
        "            \"location\": location,\n",
        "            \"date_posted\": date_posted,\n",
        "            \"description\": description,\n",
        "            \"url\": url,\n",
        "            \"is_remote\": is_remote,\n",
        "            \"tech_keywords\": tech_kw\n",
        "        })\n",
        "\n",
        "    if stop_due_to_date:\n",
        "        break\n",
        "\n",
        "# ===============================\n",
        "# Write CSV\n",
        "# ===============================\n",
        "if all_rows:\n",
        "    fieldnames = [\n",
        "        \"job_title\",\n",
        "        \"company\",\n",
        "        \"location\",\n",
        "        \"date_posted\",\n",
        "        \"description\",\n",
        "        \"url\",\n",
        "        \"is_remote\",\n",
        "        \"tech_keywords\"\n",
        "    ]\n",
        "\n",
        "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in all_rows:\n",
        "            writer.writerow(row)\n",
        "\n",
        "    print(f\"Wrote {len(all_rows)} jobs to {OUTPUT_CSV}\")\n",
        "else:\n",
        "    print(\"No jobs from the last 7 days matched the criteria.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "law6YDTaQDPy",
        "outputId": "40ea399e-b33e-4b5f-b606-aeab7f8624d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 10 jobs to job_listings_last_week_jooble.csv\n"
          ]
        }
      ]
    }
  ]
}